{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qwm-Be4BvcU9"
   },
   "source": [
    "## Recurrent Neural Networks (RNNs)\n",
    "\n",
    "Recurrent Neural Networks (RNNs) are used to model sequences of arbitrary length (e.g., sequence of words in a sentence, sequence of sentences in a document, sequence of frames in a video). RNNs typically use their internal state (memory) to process sequence of inputs. At each time-step, RNNs output a prediction and hidden state, feeding its previous hidden state into each next step. RNNs are applied in a wide range of NLP applications:\n",
    "- language modeling, where RNN can condition on **all** previous words in the corpus unlike n-gram language model\n",
    "- text classification, where the states act as features (we will see sentiment analysis in this tutorial)\n",
    "- machine translation, where a RNN is used to process a sentence in source language and another RNN is used to decode the sentence in target language (we will see this in the \"Machine Translation\" course)\n",
    "- sequence labeling, where the states in RNN are used to predict a category for each item in the sequence (we might see named entity recognition in the next tutorial)\n",
    "\n",
    "![](images/rnn.png)\n",
    "\n",
    "Picture Courtesy: https://github.com/UBC-NLP/dlnlp2019/blob/master/slides/RNN.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRPumqmgvcVB"
   },
   "source": [
    "## RNN for Classification Task \n",
    "\n",
    "We now model the text classification task of IMDB movie reviews with a vallina RNN. We'll use the RNN to sequentially process the input sequence of tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fWBhdxpvcVB"
   },
   "source": [
    "### Load Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zM9OCh9qxQJZ",
    "outputId": "1bf8778d-d95c-4031-d2dd-6b66dbac94c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0) (3.10.0.2)\n",
      "Requirement already satisfied: torchtext==0.12.0 in /usr/local/lib/python3.7/dist-packages (0.12.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.12.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.12.0) (4.63.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.12.0) (1.21.5)\n",
      "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.12.0) (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchtext==0.12.0) (3.10.0.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.12.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.12.0) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.12.0) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.12.0) (2021.10.8)\n",
      "Requirement already satisfied: torchdata==0.3.0 in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
      "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchdata==0.3.0) (1.11.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchdata==0.3.0) (2.23.0)\n",
      "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.7/dist-packages (from torchdata==0.3.0) (1.25.11)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.11.0->torchdata==0.3.0) (3.10.0.2)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata==0.3.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata==0.3.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchdata==0.3.0) (2.10)\n"
     ]
    }
   ],
   "source": [
    "# our code was tested with torch==1.11.0 and torchtext==0.12.0\n",
    "!pip install torch==1.11.0\n",
    "!pip install torchtext==0.12.0\n",
    "!pip install torchdata==0.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vr99C7zJvcVC",
    "outputId": "17a11c38-07f9-43c5-9bdf-d014145c6e4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch, torchtext\n",
    "from torch import nn, Tensor\n",
    "from torchtext.datasets import IMDB\n",
    "from torchtext.data import to_map_style_dataset\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import dataset, random_split\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jg7cNVyrvcVD"
   },
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQOhpZ1NvcVD"
   },
   "source": [
    "We use load IMDB dataset from `torchtext.datasets`. Please find more details [here](https://pytorch.org/text/stable/datasets.html#imdb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_5ns0fWcvcVE"
   },
   "outputs": [],
   "source": [
    "IMDB_train = IMDB(split=\"train\")\n",
    "IMDB_train = to_map_style_dataset(IMDB_train)\n",
    "IMDB_train, IMDB_dev = random_split(IMDB_train, [15000,10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAu-Iw3aCIbD"
   },
   "source": [
    "Show the first sample in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l_ZJ3JLtvcVE",
    "outputId": "77b6f891-e8d3-466e-f055-0ff581dbe799"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('neg',\n",
       " \"Hey HULU.com is playing the Elvira late night horror show on their site and this movie is their under the Name Monsteroid, good fun to watch Elvira comment on this Crappy movie ....Have Fun with bad movies. Anyways this movie really has very little value other than to see how bad the 70's were for horror flicks Bad Effects, Bad Dialog, just bad movie making. Avoid this unless you want to laugh at it. While you are at HULU check out the other movies that are their right now there is 10 episodes and some are pretty decent movies with good plots and production and you can watch a lot of them in 480p as long as you have a decent speed connection.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMDB_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ttA9F43wvcVF"
   },
   "source": [
    "### Create tokenizer and vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00ZN_J6ECQ2X"
   },
   "source": [
    "We use our train set to construct the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "KrbIGVfJvcVF"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "## We set the vocabulary size to 10K and includw two special tokens for unknow (<unk>) and padding (<pad>) tokens. \n",
    "vocab = build_vocab_from_iterator(map(lambda x: tokenizer(x[1]), IMDB_train), max_tokens=10000, specials=['<unk>','<pad>'])\n",
    "vocab.set_default_index(vocab['<unk>'])\n",
    "\n",
    "label2index = {'pos': 1, 'neg': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3H0lkU__D42f"
   },
   "source": [
    "Our vocabulary size is 10,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fjioQjE-vcVG",
    "outputId": "8b2ef973-4499-41fa-e75f-d5bc98f7c47c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4yDjWTFuCi31"
   },
   "source": [
    "We want to break the full sentence into individual word tokens, and get them in a format our model can handle, here is a basic way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "cXndiM5KvcVG"
   },
   "outputs": [],
   "source": [
    "from typing import List, Optional, Any, Union\n",
    "\n",
    "class default_tokenizer(nn.Module):\n",
    "    def __init__(self, tokenizer):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def forward(self, input: Any) -> Any:\n",
    "        if torch.jit.isinstance(input, List[str]):\n",
    "            tokens: List[List[str]] = []\n",
    "            for text in input:\n",
    "                tokens.append(self.tokenizer(text))\n",
    "            return tokens\n",
    "        elif torch.jit.isinstance(input, str):\n",
    "            return self.tokenizer(input)\n",
    "        else:\n",
    "            raise TypeError(\"Input type not supported\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUiAQflqDQPy"
   },
   "source": [
    "For our text processing, we will use torchtext's Transforms to apply the tokenization and mapping to ID in sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dSvmYF_9vcVH"
   },
   "outputs": [],
   "source": [
    "import torchtext.transforms as T\n",
    "\n",
    "# prepare a container to host a sequence of text transforms. We use our vocabulary and set the maximal sequence\n",
    "# length to 128. The T.Sequential() will convert string words to ids.\n",
    "processor = T.Sequential(\n",
    "    default_tokenizer(tokenizer),\n",
    "    T.VocabTransform(vocab),\n",
    "    T.Truncate(128)\n",
    "    )\n",
    "\n",
    "# Transform labels from string names to ids.\n",
    "label_processor = T.Sequential(\n",
    "    T.LabelToIndex(['pos','neg'] ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-sn2igEFCpK"
   },
   "source": [
    "Now, we create a dataloader to generate batches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xycvc45ovcVH"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_label, _text) in batch:\n",
    "        label_list.append(label_processor(_label))\n",
    "        processed_text = torch.tensor(processor(_text))\n",
    "        text_list.append(processed_text)\n",
    "    return torch.tensor(label_list), pad_sequence(text_list, padding_value=vocab.__getitem__(\"<pad>\"))\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(list(IMDB_train), batch_size=16, shuffle=True, \n",
    "                              collate_fn=collate_batch)\n",
    "dev_dataloader = DataLoader(list(IMDB_dev), batch_size=16, shuffle=False, \n",
    "                              collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uTyiOKGfEUlh"
   },
   "source": [
    "As we memtioned in previous tutorial, we can find that first element is a tensor of labels with a size of `[batch_size]` and the second element is a tensor of input sequences with a size of `[length, batch_size]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEf17wLwvcVH",
    "outputId": "8ce3aea6-2b88-4320-9eb7-a478bd5a0f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1]), tensor([[3334,  320, 3594,  ...,   46,  607,   14],\n",
      "        [ 132,   23,   78,  ...,   17, 2141,   21],\n",
      "        [  34,   15,  824,  ...,    6,   21,    0],\n",
      "        ...,\n",
      "        [4465,   20,  150,  ...,    0,    0,   88],\n",
      "        [ 420,   11,  824,  ...,  405,  144,  278],\n",
      "        [   0,    4,    3,  ..., 8146,   25,   89]]))\n",
      "torch.Size([16])\n",
      "torch.Size([128, 16])\n"
     ]
    }
   ],
   "source": [
    "for item in train_dataloader:\n",
    "    print(item)\n",
    "    print(item[0].shape)\n",
    "    print(item[1].shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8p0Rq26eIrWd"
   },
   "source": [
    "### Modules in RNN for text classification:\n",
    "1. Embedding layer\n",
    "2. RNN layer\n",
    "3. Classification layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zd9O2HOYJ3Z7"
   },
   "source": [
    "1. Embedding layer: The ``Embedding`` layer will encode each word in the vocabulary by a vector. Now, we will need to tell it what size we want for that vector. Popular values for a vector size are usally between 100-300 for many tasks. Let's set it to 300 dimensions. (You are encouraged to play with this value as practice). All words in the vocabulary will have the same embedding size. Let's put that hyper-parameter in a variable ``WORD_VEC_SIZE``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "js37C_huJ5bl"
   },
   "outputs": [],
   "source": [
    "WORD_VEC_SIZE= 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga2TYH18KAVN"
   },
   "source": [
    "We are now ready to call the ``Embedding`` class to construct an embeddings tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8a7XR3HCJ7zI",
    "outputId": "bee9651a-9b6d-44b2-ceae-a57d5755fbc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 16, 300])\n"
     ]
    }
   ],
   "source": [
    "# Constructing an embedding Layer:\n",
    "embedding = nn.Embedding(len(vocab), WORD_VEC_SIZE)\n",
    "\n",
    "# apply the embedding layer on the input of the fist batch \n",
    "input = item[1]\n",
    "embedded=embedding(input)\n",
    "print(embedded.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYFN_-VSKS-2"
   },
   "source": [
    "After the word embedding layer, the input batch is a tenor of `[sequence length, batch size, embedding size]`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WixGlGsVKnfh"
   },
   "source": [
    "2. RNN layer: PyTorch has ``torch.nn.RNN`` module that implements the vanilla (Elman) RNN with *tanh* or *ReLU* non-linearity. The documentation for this module is [here](https://pytorch.org/docs/stable/nn.html#torch.nn.RNN). Let us contine using the firt sample batch to understand this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "giqHZrHRLNzO"
   },
   "source": [
    "We define a single RNN layer with a hidden size of 50. The input_size is equal to the embedding size that is 300 in our example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tcUkSZbiLBC9"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define the RNN module\n",
    "\"\"\"\n",
    "# first input - number of dimesnions for word vectors for a vector x (300, size of the word embedding)\n",
    "# second input - number of nodes in hidden state h_t (50, size of the hidden layer)\n",
    "# third input - number of recurrent layers (we set it to 1)\n",
    "rnn_layer = nn.RNN(input_size=300, hidden_size=50, num_layers=1) # input_size, hidden_size, num_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzRXwf-RL_Zt"
   },
   "source": [
    "We will now pass the ``embedded`` tensor (representations of words in our batch) to RNN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cnboJFDUL-zb"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward propagation over the RNN model\n",
    "\"\"\"\n",
    "rnn_output, hn = rnn_layer(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D9yEcN8dMWUh"
   },
   "source": [
    "But what is ``rnn_output``? Well, let's inspect its shape first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ZpDoRA9MQC_",
    "outputId": "e939933a-c18e-43a0-a889-c2c5a6ec5862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_output size:  torch.Size([128, 16, 50])\n"
     ]
    }
   ],
   "source": [
    "# output = seq_len, batch, hidden_size (output features from last layer of RNN)\n",
    "print(\"rnn_output size: \", rnn_output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5mF33cEMbh1"
   },
   "source": [
    "Here's what we need to know about ``output``:\n",
    "- The first dimension in the ``output`` tensor is the ``sequence length`` (=128). \n",
    "- The second dimension is ``batch_size`` (the number of examples/sentences in our batch = 16).\n",
    "- The third dimension is the ``size of nodes/units`` in our hidden layer (=50). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mQreyxqkMsv4"
   },
   "source": [
    "Here's what we need to know about ``hn``:\n",
    "- ``hn`` is a tensor of shape `[num_layers, batch size, hidden size]` containing the hidden state for the last ``time step`` \n",
    "(``t = max_seq_length``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CYGIUZhIM078",
    "outputId": "cad6fd1f-9c64-492d-af7c-fd0916bb6a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last hidden state size:  torch.Size([1, 16, 50])\n"
     ]
    }
   ],
   "source": [
    "# h_n = num_layers, batch, hidden_size (hidden state for t=seq_len or hidden state at last timestep)\n",
    "print(\"last hidden state size: \", hn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rZvbwjpPNMTo"
   },
   "source": [
    "You can take the output representation for a text sequence after processing the last token (t=seq_len or last timestep) and call the resulting representation as the tweet representation that **\"summarizes\" the information present** in the text. This text representation can further be used for the text classification.\n",
    "\n",
    "Let us compute the final tweet representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "juZKQvXiNqjH",
    "outputId": "34ed4551-44da-46c8-89c8-9bf263a2871b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text output embeddings size:  torch.Size([16, 50])\n"
     ]
    }
   ],
   "source": [
    "text_output_embeddings = rnn_output[-1,:,:] # -1 fetches the embeddings from the last timestep\n",
    "print(\"text output embeddings size: \", text_output_embeddings.size())\n",
    "# first dimension - number of tweets in the batch (16)\n",
    "# second dimension - number of features in hidden state h_t (50, size of the hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "O5HHm0KQQbYr"
   },
   "outputs": [],
   "source": [
    "## Apply a ReLU non-linearity\n",
    "activation_fn = nn.ReLU()\n",
    "text_output_embeddings = activation_fn(text_output_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2bOxt2YOK-s"
   },
   "source": [
    "3. Classification layer: Finanlly, we pass the text representation (i.e., `text_output_embeddings`) through a feed-forward layer with a softmax activation function for the classification task. The input size is the hidden size of the text representation. The output dimension must be the size of the label set (i.e., 2 for our task)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "C1LisyD7OlOR"
   },
   "outputs": [],
   "source": [
    "output_linear_layer = nn.Linear(50, 2) \n",
    "softmax_layer = nn.Softmax(dim=1) \n",
    "# Softmax normalizes vectors along the class dimension so they can represent probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "UUAnDeg4Pl37"
   },
   "outputs": [],
   "source": [
    "logit = output_linear_layer(text_output_embeddings)\n",
    "prob_out = softmax_layer(logit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGRw_M4AP8nx"
   },
   "source": [
    "Finally, the prediction output is a tenor of `[batch size, number of classes]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PpRXcef6P8-J",
    "outputId": "a5501fd8-3187-4c6a-c621-4a5a8069ba59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2])\n",
      "tensor([0.4834, 0.5166], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(prob_out.shape)\n",
    "print(prob_out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PBvaAO3z8Wk"
   },
   "source": [
    "#### Calculating Loss: We now use [`CrossEntropyLoss()`](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html) loss function to calculate the loss of the first batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YXJcaUhVzjkj",
    "outputId": "8a0e94e2-2962-44b7-cae3-dfc126c96808"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6962, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criteria = nn.CrossEntropyLoss()\n",
    "criteria(prob_out, item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwyeZQRuSj5G"
   },
   "source": [
    "### Train a RNN with the whole dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YIj0cAhSFRKO"
   },
   "source": [
    "Let's re-use our training code from earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iJc8M15vvcVI"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "\n",
    "def train(loader, model, criterion, optimizer, device):\n",
    "    total_loss = 0.0\n",
    "    num_sample = 0\n",
    "    for batch in loader:\n",
    "        # load the current batch\n",
    "        batch_output, batch_input = batch  #unpack the batch\n",
    "\n",
    "        batch_input = batch_input.to(device)\n",
    "        batch_output = batch_output.to(device)\n",
    "        # forward propagation\n",
    "        # pass the data through the model\n",
    "        model_outputs = model(batch_input)\n",
    "        # compute the loss\n",
    "        cur_loss = criterion(model_outputs, batch_output)\n",
    "        total_loss += cur_loss.item()\n",
    "\n",
    "        # backward propagation (compute the gradients and update the model)\n",
    "        # clear the buffer\n",
    "        optimizer.zero_grad()\n",
    "        # compute the gradients\n",
    "        cur_loss.backward()\n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        num_sample += batch_output.shape[0]\n",
    "    return total_loss / num_sample\n",
    "\n",
    "\n",
    "# evaluation logic based on classification accuracy\n",
    "def evaluate(loader, model, device):\n",
    "    all_pred = []\n",
    "    all_label = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            # load the current batch\n",
    "            batch_output, batch_input = batch\n",
    "\n",
    "            batch_input = batch_input.to(device)\n",
    "            # forward propagation\n",
    "            # pass the data through the model\n",
    "            model_outputs = model(batch_input)\n",
    "            # identify the predicted class for each example in the batch\n",
    "            probabilities, predicted = torch.max(model_outputs.cpu().data, 1)\n",
    "            # put all the true labels and predictions to two lists\n",
    "            all_pred.extend(predicted)\n",
    "            all_label.extend(batch_output)\n",
    "\n",
    "    accuracy = accuracy_score(all_label, all_pred)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "efV42dKuFuBK"
   },
   "source": [
    "#### Model class object\n",
    "\n",
    "We initialize the modules of a RNN and define its computation forward graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "RWqySc31vcVI"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create a model for RNN\n",
    "\"\"\"\n",
    "class RNNmodel(nn.Module):\n",
    "  \n",
    "  def __init__(self, embedding_size, vocab_size, output_size, hidden_size, num_layers):\n",
    "    # In the constructor we define the layers for our model\n",
    "    super(RNNmodel, self).__init__()\n",
    "    # word embedding lookup table\n",
    "    self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_size)\n",
    "    # core RNN module\n",
    "    self.rnn_layer = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers) \n",
    "    # activation function\n",
    "    self.activation_fn = nn.ReLU()\n",
    "    # classification related modules\n",
    "    self.output_linear_layer = nn.Linear(hidden_size, output_size) \n",
    "    self.softmax_layer = nn.Softmax(dim=1)\n",
    "  \n",
    "  def forward(self, x):\n",
    "    # In the forward function we define the forward propagation logic\n",
    "    embedded = self.embedding(x)\n",
    "    rnn_output, hn = self.rnn_layer(embedded) # since we are not feeding h_0 explicitly, h_0 will be initialized to zeros by default\n",
    "    # classify based on the hidden representation after RNN processes the last token\n",
    "    text_output_embeddings = rnn_output[-1, :, :]\n",
    "    text_output_embeddings = self.activation_fn(text_output_embeddings)\n",
    "    logit = self.output_linear_layer(text_output_embeddings)\n",
    "    prob_out = self.softmax_layer(logit) # Softmax normalizes vectors so they can represent probabilities\n",
    "    \n",
    "    return prob_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVkDoYgGF_oH"
   },
   "source": [
    "#### Instantiate our RNN model\n",
    "\n",
    "We define the hyper-parameters of a RNN model and instantiate it. We then create the loss function and optimization method for back-propagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pQlV3I6evcVI"
   },
   "outputs": [],
   "source": [
    "# set the seed\n",
    "manual_seed = 123\n",
    "torch.manual_seed(manual_seed)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "if n_gpu > 0:\n",
    "    torch.cuda.manual_seed(manual_seed)\n",
    "\n",
    "# hyperparameters\n",
    "MAX_EPOCHS = 30\n",
    "LEARNING_RATE = 0.1\n",
    "NUM_CLASSES = 2\n",
    "WORD_VEC_SIZE = 300\n",
    "\n",
    "# hyperparameters of RNN\n",
    "HIDDEN_SIZE = 50\n",
    "NUM_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "0hSwyA0WvcVJ"
   },
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = RNNmodel(WORD_VEC_SIZE, len(vocab), NUM_CLASSES, HIDDEN_SIZE, NUM_LAYERS) \n",
    "model.to(device)\n",
    "# define the loss function (last node of the graph)\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJpt69UTGm0e"
   },
   "source": [
    "Before we train, let's look a little bit more at our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g8qfgQXgGmhw",
    "outputId": "6d713265-cef4-423d-f68b-ba2035c5c566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entire model looks like this: \n",
      "RNNmodel(\n",
      "  (embedding): Embedding(10000, 300)\n",
      "  (rnn_layer): RNN(300, 50)\n",
      "  (activation_fn): ReLU()\n",
      "  (output_linear_layer): Linear(in_features=50, out_features=2, bias=True)\n",
      "  (softmax_layer): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"The entire model looks like this: \")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MbZy9xaMvcVJ",
    "outputId": "19ab0cfa-633f-4449-c3fc-ecd3d4674c41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 results: Loss 0.04348437851667404, Train Acc: 0.5426666666666666, Val Acc: 0.5115\n",
      "Epoch 2 results: Loss 0.04316027115980784, Train Acc: 0.5464, Val Acc: 0.5127\n",
      "Epoch 3 results: Loss 0.04274950860738754, Train Acc: 0.5930666666666666, Val Acc: 0.5225\n",
      "Epoch 4 results: Loss 0.042166907087961836, Train Acc: 0.6117333333333334, Val Acc: 0.5211\n",
      "Epoch 5 results: Loss 0.04155435821612676, Train Acc: 0.645, Val Acc: 0.5258\n",
      "Epoch 6 results: Loss 0.04079908226927122, Train Acc: 0.6567333333333333, Val Acc: 0.5364\n",
      "Epoch 7 results: Loss 0.04003157585859299, Train Acc: 0.6681333333333334, Val Acc: 0.5302\n",
      "Epoch 8 results: Loss 0.03935043823122978, Train Acc: 0.6987333333333333, Val Acc: 0.5341\n",
      "Epoch 9 results: Loss 0.03858729357719421, Train Acc: 0.7048, Val Acc: 0.5344\n",
      "Epoch 10 results: Loss 0.03800934056242307, Train Acc: 0.6915333333333333, Val Acc: 0.5218\n",
      "Epoch 11 results: Loss 0.0373943032681942, Train Acc: 0.7280666666666666, Val Acc: 0.5299\n",
      "Epoch 12 results: Loss 0.03675204685529073, Train Acc: 0.7276666666666667, Val Acc: 0.5328\n",
      "Epoch 13 results: Loss 0.03630959044893583, Train Acc: 0.7390666666666666, Val Acc: 0.5303\n",
      "Epoch 14 results: Loss 0.03574542198578517, Train Acc: 0.7563333333333333, Val Acc: 0.532\n",
      "Epoch 15 results: Loss 0.03542217492262523, Train Acc: 0.7555333333333333, Val Acc: 0.5261\n",
      "Epoch 16 results: Loss 0.03489875663518906, Train Acc: 0.7585333333333333, Val Acc: 0.5274\n",
      "Epoch 17 results: Loss 0.03465135489503542, Train Acc: 0.7750666666666667, Val Acc: 0.5328\n",
      "Epoch 18 results: Loss 0.034302022115389505, Train Acc: 0.7787333333333334, Val Acc: 0.5363\n",
      "Epoch 19 results: Loss 0.034243950988849005, Train Acc: 0.7624666666666666, Val Acc: 0.517\n",
      "Epoch 20 results: Loss 0.03400447563926379, Train Acc: 0.7828666666666667, Val Acc: 0.5351\n",
      "Epoch 21 results: Loss 0.03363930536905924, Train Acc: 0.7823333333333333, Val Acc: 0.5334\n",
      "Epoch 22 results: Loss 0.03367765459616979, Train Acc: 0.7815333333333333, Val Acc: 0.5271\n",
      "Epoch 23 results: Loss 0.03340102941393852, Train Acc: 0.7904666666666667, Val Acc: 0.5371\n",
      "Epoch 24 results: Loss 0.03307637646794319, Train Acc: 0.8015333333333333, Val Acc: 0.5347\n",
      "Epoch 25 results: Loss 0.03296967048048973, Train Acc: 0.7857333333333333, Val Acc: 0.5388\n",
      "Epoch 26 results: Loss 0.03282808810869853, Train Acc: 0.7999333333333334, Val Acc: 0.5308\n",
      "Epoch 27 results: Loss 0.032733520569403964, Train Acc: 0.804, Val Acc: 0.5387\n",
      "Epoch 28 results: Loss 0.032439461408058805, Train Acc: 0.8065333333333333, Val Acc: 0.54\n",
      "Epoch 29 results: Loss 0.03242208670973778, Train Acc: 0.7968, Val Acc: 0.5317\n",
      "Epoch 30 results: Loss 0.0323840444068114, Train Acc: 0.8008666666666666, Val Acc: 0.5409\n"
     ]
    }
   ],
   "source": [
    "results = {\"epoch\": [], \"loss\" : [], \"train acc\" : [], \"val acc\" :[]}\n",
    "for i in range(MAX_EPOCHS):\n",
    "    loss = train(train_dataloader, model, criteria, optimizer, device)\n",
    "    train_acc = evaluate(train_dataloader, model, device)\n",
    "    val_acc = evaluate(dev_dataloader, model, device)\n",
    "    results[\"epoch\"].append(i)\n",
    "    results[\"loss\"].append(loss)\n",
    "    results['train acc'].append(train_acc)\n",
    "    results['val acc'].append(val_acc)\n",
    "    \n",
    "    print(\"Epoch {} results: Loss {}, Train Acc: {}, Val Acc: {}\".format(i+1, loss, train_acc, val_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "tWSws7qEvcVJ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "bluSa764vcVJ",
    "outputId": "97fcfb8c-2f6d-4e34-9221-b69d4e2b362e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "color = 'tab:red'\n",
    "loss_line, = ax1.plot(results[\"epoch\"],results[\"loss\"], linewidth=1.0, color=color, label= \"loss\")\n",
    "ax1.set(xlim=(0, 30), xticks=np.arange(0, 30, 5),\n",
    "       ylim=(0.03, 0.05))                                 \n",
    "ax1.set_ylabel('loss', color=color)                             \n",
    "ax1.set_xlabel('epochs')\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "\n",
    "train_line, = ax2.plot(results[\"epoch\"],results[\"train acc\"], linewidth=1.0, label='train acc')\n",
    "val_line, = ax2.plot(results[\"epoch\"],results[\"val acc\"], linewidth=1.0, label='val acc')\n",
    "ax2.set(xlim=(0, 30), xticks=np.arange(0, 30, 5),\n",
    "       ylim=(0.5, 1))\n",
    "ax2.set_ylabel('accuracy')\n",
    "\n",
    "p = [val_line, train_line, loss_line]\n",
    "ax2.legend(p, [p_.get_label() for p_ in p])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V-7bPhavcVK"
   },
   "source": [
    "## GRUs\n",
    "\n",
    "Gated Recurrent Units (GRUs) are a variant of RNNs that use more complex units for activation. They are created to have more persistent memory thereby making them easier for RNNs to capture long-term dependencies. To learn the theory behind GRUs, we recommend: https://github.com/UBC-NLP/dlnlp2019/blob/master/slides/RNN.pdf \n",
    "\n",
    "GRU is defined by ``torch.nn.GRU`` module and its documentation can be fetched [here](https://pytorch.org/docs/stable/nn.html#torch.nn.GRU). Now let us define the GRU module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "jcNkXTgwvcVK"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define the GRU module\n",
    "\"\"\"\n",
    "# first input - number of word vector dimensions/embeddings\n",
    "# second input - number of nodes in hidden layer (50, size of the hidden layer)\n",
    "# third input - number of recurrent layers (2)\n",
    "gru_rnn = nn.GRU(input_size=300, hidden_size=50, num_layers=1) # input_size, hidden_size, num_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sm99BCQKvcVK"
   },
   "source": [
    "Similar to RNN, GRU module takes two inputs: *the initial hidden state for each element in the batch* (t=0) and the *input features* (``tweet_input_embeddings`` in our case).\n",
    "\n",
    "Let us feed the sequence embeddings to our GRU model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "c-MvvT6NvcVK"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward propagation over the GRU model\n",
    "\"\"\"\n",
    "output, hn = gru_rnn(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HCZFMddxUKvd",
    "outputId": "8504b62b-9e2e-493f-fe04-fe008afb9043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size:  torch.Size([128, 16, 50])\n",
      "last hidden state size:  torch.Size([1, 16, 50])\n"
     ]
    }
   ],
   "source": [
    "# output = seq_len, batch, hidden_size (output features from last layer of GRU)\n",
    "print(\"output size: \", output.size())\n",
    "\n",
    "# h_n = num_layers, batch, hidden_size (hidden state for t=seq_len or hidden state at last timestep)\n",
    "print(\"last hidden state size: \", hn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TT0qmUtAvcVM"
   },
   "source": [
    "## LSTMs\n",
    "\n",
    "Long short-term memory (LSTMs) are a variant of RNNs that use more complex units for activation. Similar to the spirit of GRU, they are created to have more persistent memory thereby making them easier for RNNs to capture long-term dependencies. To learn the theory behind GRUs, we recommend: https://github.com/UBC-NLP/dlnlp2019/blob/master/slides/RNN.pdf \n",
    "\n",
    "LSTM is defined by ``torch.nn.LSTM`` module and its documentation can be fetched [here](https://pytorch.org/docs/stable/nn.html#torch.nn.LSTM). Now let us define the LSTM module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "SfXmvr0kvcVM"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "define the LSTM module\n",
    "\"\"\"\n",
    "# first input - number of features in x (300, size of the word embedding)\n",
    "# second input - number of number of nodes in a hidden layer (50)\n",
    "# third input - number of recurrent layers (2)\n",
    "lstm_rnn = nn.LSTM(input_size=300, hidden_size=50, num_layers=2) # input_size, hidden_size, num_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPCTyyX8vcVN"
   },
   "source": [
    "Let us feed the sequence embeddings to our LSTM model. Unlike RNN and GRU, LSTM module has three output: `output, hn, and cn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "RFSCBlzHvcVN"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "forward propagation over the LSTM model\n",
    "\"\"\"\n",
    "output, (hn, cn) = lstm_rnn(embedded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtbdPFNgT1Hi"
   },
   "source": [
    "``output`` tensor contains the output features $h_t$ from the last layer of the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pdf-po_JTz2M",
    "outputId": "69a20bdb-956c-4189-aec1-4ab142c76847"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size:  torch.Size([128, 16, 50])\n"
     ]
    }
   ],
   "source": [
    "# output = seq_len, batch_size, hidden_size (output features from last layer of LSTM)\n",
    "print(\"output size: \", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bd3lx5ywT5jk"
   },
   "source": [
    "``hn`` is a tensor of shape `[num_layers, batch size, hidden_size]` containing the hidden state for t = seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrS5UHZlT3ME",
    "outputId": "273c8d93-5b87-42ef-8ace-07c79771e19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last hidden state size:  torch.Size([2, 16, 50])\n"
     ]
    }
   ],
   "source": [
    "# h_n = num_layers, batch, hidden_size (hidden state for t=seq_len or hidden state at last timestep)\n",
    "print(\"last hidden state size: \", hn.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Zezmv1CUAoZ"
   },
   "source": [
    "``cn`` is a tensor of shape (num_layers, batch, hidden_size) containing the cell state for t = seq_len."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AyLPZAx1UABg",
    "outputId": "a582e907-f8d5-4a4a-99fb-ee6791e008c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last cell state size:  torch.Size([2, 16, 50])\n"
     ]
    }
   ],
   "source": [
    "# c_n = num_layers, batch_size, hidden_size (cell state for t=seq_len or cell state at last timestep)\n",
    "print(\"last cell state size: \", hn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "7z9ze-54UEW3"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "RNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
